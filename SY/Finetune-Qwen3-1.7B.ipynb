{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environment/SY/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: optimum-neuron==0.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: peft==0.16.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: trl==0.11.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.11.4)\n",
      "Requirement already satisfied: huggingface_hub==0.33.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.33.4)\n",
      "Requirement already satisfied: datasets==3.6.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: transformers~=4.51.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (4.51.3)\n",
      "Requirement already satisfied: accelerate==1.8.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: optimum~=1.24.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (1.24.0)\n",
      "Requirement already satisfied: numpy<=1.25.2,>=1.22.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (1.25.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: psutil in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (2.7.0)\n",
      "Requirement already satisfied: tqdm in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: safetensors in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from trl==0.11.4->-r requirements.txt (line 3)) (0.9.35)\n",
      "Requirement already satisfied: filelock in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2025.3.0)\n",
      "Requirement already satisfied: requests in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (3.12.15)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from transformers~=4.51.0->optimum-neuron==0.3.0->-r requirements.txt (line 1)) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from transformers~=4.51.0->optimum-neuron==0.3.0->-r requirements.txt (line 1)) (0.21.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests->huggingface_hub==0.33.4->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests->huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests->huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2025.7.14)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from triton==3.3.0->torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (14.1.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (4.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0->-r requirements.txt (line 5)) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/environment/SY/assets\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consolidate_adapter_shards_and_merge_model.py  finetune_model.py\n",
      "finetune_emergency_response.py                 requirements.txt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "\n",
    "In this section, we fine-tune the Qwen3-1.7B model on the Text-to-SQL task using Hugging Face Optimum Neuron. Here are the parameters we are going to pass - \n",
    "\n",
    "1. `--nnodes`:\tNumber of nodes (1 = single node)\n",
    "2. `--nproc_per_node`: \tProcesses per node (usually equals number of devices).\n",
    "3. `--model_id, --tokenizer_id`:\tModel and tokenizer identifiers (from Hugging Face or local path).\n",
    "4. `--output_dir`:\tDirectory for saving checkpoints and logs.\n",
    "5. `--bf16`:\tEnables bfloat16 precision for faster, memory-efficient training.\n",
    "5. `--gradient_checkpointing`:\tSaves memory by recomputing activations during backprop.\n",
    "6. `--gradient_accumulation_steps`:\tSteps to accumulate gradients before optimizer update.\n",
    "7. `--learning_rate`:\tInitial training learning rate.\n",
    "8. `--max_steps`:\tTotal number of training steps.\n",
    "9. `--per_device_train_batch_size`:\tBatch size per device.\n",
    "10. `--tensor_parallel_size`:\tNumber of devices for tensor parallelism.\n",
    "11. `--lora_r, --lora_alpha, --lora_dropout`:\tLoRA hyperparameters â€” rank, scaling, and dropout rate.\n",
    "12. `--dataloader_drop_last`:\tDrops last incomplete batch.\n",
    "13. `--disable_tqdm`: Disables progress bar.\n",
    "14. `--logging_steps`:\tLog interval (in steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1108 23:16:05.432000 195526 /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/distributed/run.py:766] \n",
      "W1108 23:16:05.432000 195526 /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/distributed/run.py:766] *****************************************\n",
      "W1108 23:16:05.432000 195526 /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1108 23:16:05.432000 195526 /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/distributed/run.py:766] *****************************************\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "2025-11-08 23:16:16.093008: W neuron/nrt_adaptor.cc:53] nrt_tensor_write_hugepage() is not available, will fall back to nrt_tensor_write().\n",
      "2025-11-08 23:16:16.093043: W neuron/nrt_adaptor.cc:62] nrt_tensor_read_hugepage() is not available, will fall back to nrt_tensor_read().\n",
      "2025-Nov-08 23:16:16.0095 195542:195601 [1] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):213 CCOM WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "2025-Nov-08 23:16:16.0105 195542:195601 [1] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):354 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2025-Nov-08 23:16:16.0115 195542:195601 [1] ncclResult_t nccl_net_ofi_init_no_atexit_fini_v6(ncclDebugLogger_t):183 CCOM WARN NET/OFI Initializing plugin failed\n",
      "2025-Nov-08 23:16:16.0125 195542:195601 [1] net_plugin.cc:97 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
      "2025-11-08 23:16:30.756615: W neuron/nrt_adaptor.cc:53] nrt_tensor_write_hugepage() is not available, will fall back to nrt_tensor_write().\n",
      "2025-11-08 23:16:30.756652: W neuron/nrt_adaptor.cc:62] nrt_tensor_read_hugepage() is not available, will fall back to nrt_tensor_read().\n",
      "2025-Nov-08 23:16:30.0758 195541:195632 [0] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):213 CCOM WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "2025-Nov-08 23:16:30.0768 195541:195632 [0] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):354 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2025-Nov-08 23:16:30.0778 195541:195632 [0] ncclResult_t nccl_net_ofi_init_no_atexit_fini_v6(ncclDebugLogger_t):183 CCOM WARN NET/OFI Initializing plugin failed\n",
      "2025-Nov-08 23:16:30.0788 195541:195632 [0] net_plugin.cc:97 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
      "[2025-11-08 23:16:30.886: I neuronx_distributed/parallel_layers/parallel_state.py:628] > initializing tensor model parallel with size 2\n",
      "[2025-11-08 23:16:30.887: I neuronx_distributed/parallel_layers/parallel_state.py:629] > initializing pipeline model parallel with size 1\n",
      "[2025-11-08 23:16:30.887: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing context model parallel with size 1\n",
      "[2025-11-08 23:16:30.887: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing data parallel with size 1\n",
      "[2025-11-08 23:16:30.887: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing world size to 2\n",
      "2025-11-08 23:16:30.000949:  195541  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_910320559639473753+e30acd3a/model.neff\n",
      "2025-11-08 23:16:30.000949:  195542  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_910320559639473753+e30acd3a/model.neff\n",
      "[2025-11-08 23:16:30.991: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7531dca72950>, 'Ascending Ring PG Group')>\n",
      "[2025-11-08 23:16:30.992: I neuronx_distributed/parallel_layers/parallel_state.py:668] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1]]\n",
      "[2025-11-08 23:16:30.992: I neuronx_distributed/parallel_layers/parallel_state.py:669] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1]]\n",
      "[2025-11-08 23:16:30.992: I neuronx_distributed/parallel_layers/parallel_state.py:670] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1]]\n",
      "[2025-11-08 23:16:30.992: I neuronx_distributed/parallel_layers/parallel_state.py:671] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1]]\n",
      "[2025-11-08 23:16:30.992: I neuronx_distributed/parallel_layers/parallel_state.py:672] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1]]\n",
      "[2025-11-08 23:16:30.992: I neuronx_distributed/parallel_layers/parallel_state.py:673] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1]]\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "No Hugging Face token found in environment, checking AWS Secrets Manager...\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "No Hugging Face token found in environment, checking AWS Secrets Manager...\n",
      "Logging in to Hugging Face Hub...\n",
      "Logging in to Hugging Face Hub...\n",
      "Loading dataset...\n",
      "Loading dataset...\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68119/68119 [00:04<00:00, 15146.25 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7569/7569 [00:00<00:00, 12728.12 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68119/68119 [00:05<00:00, 12490.31 examples/s]\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/kvcache/kv_cache_manager.py:24: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..attention.gqa import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/kvcache/kv_cache_manager.py:24: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..attention.gqa import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:45: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:45: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.81s/it]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.27s/it]\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/transformers/training_args.py:2058: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/transformers/training_args.py:2058: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "Generating train split: 23775 examples [00:27, 877.46 examples/s] \n",
      "Generating train split: 2648 examples [00:02, 899.66 examples/s] \n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py:1467: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `NeuronSFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer.__init__(self, *args, **kwargs)\n",
      "No label_names provided for model class `NeuronPeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py:1726: UserWarning: You passed `packing=True` to the SFTTrainer/SFTConfig, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py:1467: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `NeuronSFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer.__init__(self, *args, **kwargs)\n",
      "No label_names provided for model class `NeuronPeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py:1726: UserWarning: You passed `packing=True` to the SFTTrainer/SFTConfig, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 23,775\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Total optimization steps = 3,500\n",
      "  Number of trainable parameters = 16,515,072\n",
      "2025-11-08 23:17:35.000747:  195541  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_14152517080381013961+a3455b04/model.neff\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "2025-11-08 23:17:35.000892:  195542  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_14152517080381013961+a3455b04/model.neff\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "2025-11-08 23:17:38.000392:  195542  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_14770574952780443587+a3455b04/model.neff\n",
      "2025-11-08 23:17:38.000395:  195541  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_13340102934497073113+a3455b04/model.neff\n",
      "2025-11-08 23:17:44.000090:  195541  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_6394509931854585423+a3455b04/model.neff\n",
      "2025-11-08 23:17:44.000118:  195542  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_4493465029485591167+a3455b04/model.neff\n",
      "2025-11-08 23:17:53.000312:  195541  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_17239445601988651504+a3455b04/model.neff\n",
      "2025-11-08 23:17:53.000477:  195542  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_5391683354399705816+a3455b04/model.neff\n",
      "2025-11-08 23:17:59.000995:  195541  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_3188978248012181906+a3455b04/model.neff\n",
      "2025-11-08 23:18:00.000514:  195542  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_3188978248012181906+a3455b04/model.neff\n",
      "2025-11-08 23:18:03.000887:  195542  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_9123409164792130896+a3455b04/model.neff\n",
      "2025-11-08 23:18:03.000894:  195541  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_9123409164792130896+a3455b04/model.neff\n",
      "2025-11-08 23:18:14.000210:  195542  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_9654582282420716943+a3455b04/model.neff\n",
      "2025-11-08 23:18:14.000217:  195541  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_9654582282420716943+a3455b04/model.neff\n",
      "{'loss': 2.425, 'learning_rate': 4.985714285714286e-05, 'grad_norm': 3.203125, 'epoch': 0.0008412551526878103}\n",
      "{'loss': 1.7887, 'learning_rate': 4.971428571428572e-05, 'grad_norm': 0.66796875, 'epoch': 0.0016825103053756205}\n",
      "{'loss': 1.6127, 'learning_rate': 4.957142857142857e-05, 'grad_norm': 0.5390625, 'epoch': 0.002523765458063431}\n",
      "{'loss': 1.5817, 'learning_rate': 4.942857142857143e-05, 'grad_norm': 0.54296875, 'epoch': 0.003365020610751241}\n",
      "{'loss': 1.5663, 'learning_rate': 4.928571428571429e-05, 'grad_norm': 0.60546875, 'epoch': 0.004206275763439051}\n",
      "{'loss': 1.4757, 'learning_rate': 4.9142857142857144e-05, 'grad_norm': 0.57421875, 'epoch': 0.005047530916126862}\n",
      "{'loss': 1.3128, 'learning_rate': 4.9e-05, 'grad_norm': 0.55078125, 'epoch': 0.005888786068814672}\n",
      "{'loss': 1.3382, 'learning_rate': 4.885714285714286e-05, 'grad_norm': 0.51171875, 'epoch': 0.006730041221502482}\n",
      "{'loss': 1.2094, 'learning_rate': 4.8714285714285714e-05, 'grad_norm': 0.64453125, 'epoch': 0.0075712963741902915}\n",
      "{'loss': 1.2194, 'learning_rate': 4.8571428571428576e-05, 'grad_norm': 0.546875, 'epoch': 0.008412551526878103}\n",
      "{'loss': 1.3064, 'learning_rate': 4.842857142857143e-05, 'grad_norm': 0.73046875, 'epoch': 0.009253806679565912}\n",
      "{'loss': 1.16, 'learning_rate': 4.828571428571429e-05, 'grad_norm': 0.63671875, 'epoch': 0.010095061832253723}\n",
      "{'loss': 1.1823, 'learning_rate': 4.8142857142857147e-05, 'grad_norm': 0.5546875, 'epoch': 0.010936316984941533}\n",
      "{'loss': 1.3012, 'learning_rate': 4.8e-05, 'grad_norm': 0.5703125, 'epoch': 0.011777572137629344}\n",
      "{'loss': 1.163, 'learning_rate': 4.785714285714286e-05, 'grad_norm': 0.5546875, 'epoch': 0.012618827290317153}\n",
      "{'loss': 1.2928, 'learning_rate': 4.771428571428572e-05, 'grad_norm': 0.53125, 'epoch': 0.013460082443004964}\n",
      "{'loss': 1.0463, 'learning_rate': 4.757142857142857e-05, 'grad_norm': 0.59375, 'epoch': 0.014301337595692774}\n",
      "{'loss': 1.2073, 'learning_rate': 4.742857142857143e-05, 'grad_norm': 0.6796875, 'epoch': 0.015142592748380583}\n",
      "{'loss': 1.1335, 'learning_rate': 4.728571428571429e-05, 'grad_norm': 0.59375, 'epoch': 0.015983847901068392}\n",
      "{'loss': 1.0607, 'learning_rate': 4.714285714285714e-05, 'grad_norm': 0.515625, 'epoch': 0.016825103053756205}\n",
      "{'loss': 1.2663, 'learning_rate': 4.7e-05, 'grad_norm': 0.6171875, 'epoch': 0.017666358206444015}\n",
      "{'loss': 1.1706, 'learning_rate': 4.685714285714286e-05, 'grad_norm': 0.6484375, 'epoch': 0.018507613359131824}\n",
      "{'loss': 1.1455, 'learning_rate': 4.671428571428571e-05, 'grad_norm': 0.6015625, 'epoch': 0.019348868511819634}\n",
      "{'loss': 1.1537, 'learning_rate': 4.6571428571428575e-05, 'grad_norm': 0.61328125, 'epoch': 0.020190123664507446}\n",
      "{'loss': 1.0919, 'learning_rate': 4.642857142857143e-05, 'grad_norm': 0.6640625, 'epoch': 0.021031378817195256}\n",
      "{'loss': 1.071, 'learning_rate': 4.628571428571429e-05, 'grad_norm': 0.58984375, 'epoch': 0.021872633969883065}\n",
      "{'loss': 1.1787, 'learning_rate': 4.6142857142857145e-05, 'grad_norm': 0.6171875, 'epoch': 0.022713889122570875}\n",
      "{'loss': 1.205, 'learning_rate': 4.600000000000001e-05, 'grad_norm': 0.5078125, 'epoch': 0.023555144275258687}\n",
      "{'loss': 1.1061, 'learning_rate': 4.585714285714286e-05, 'grad_norm': 0.6796875, 'epoch': 0.024396399427946497}\n",
      "{'loss': 1.2128, 'learning_rate': 4.5714285714285716e-05, 'grad_norm': 0.671875, 'epoch': 0.025237654580634306}\n",
      "{'loss': 1.2532, 'learning_rate': 4.557142857142858e-05, 'grad_norm': 0.6484375, 'epoch': 0.026078909733322116}\n",
      "{'loss': 1.1005, 'learning_rate': 4.542857142857143e-05, 'grad_norm': 0.7109375, 'epoch': 0.02692016488600993}\n",
      "{'loss': 1.1061, 'learning_rate': 4.528571428571429e-05, 'grad_norm': 0.765625, 'epoch': 0.027761420038697738}\n",
      "{'loss': 1.1136, 'learning_rate': 4.514285714285714e-05, 'grad_norm': 0.66015625, 'epoch': 0.028602675191385547}\n",
      "{'loss': 1.2706, 'learning_rate': 4.5e-05, 'grad_norm': 1.046875, 'epoch': 0.029443930344073357}\n",
      "{'loss': 1.1717, 'learning_rate': 4.485714285714286e-05, 'grad_norm': 0.6953125, 'epoch': 0.030285185496761166}\n",
      "{'loss': 1.0498, 'learning_rate': 4.471428571428571e-05, 'grad_norm': 0.5703125, 'epoch': 0.03112644064944898}\n",
      "{'loss': 1.1341, 'learning_rate': 4.4571428571428574e-05, 'grad_norm': 0.7578125, 'epoch': 0.031967695802136785}\n",
      "{'loss': 1.3294, 'learning_rate': 4.442857142857143e-05, 'grad_norm': 0.6171875, 'epoch': 0.0328089509548246}\n",
      "{'loss': 0.9689, 'learning_rate': 4.428571428571428e-05, 'grad_norm': 0.5859375, 'epoch': 0.03365020610751241}\n",
      "{'loss': 1.1241, 'learning_rate': 4.4142857142857144e-05, 'grad_norm': 0.6875, 'epoch': 0.03449146126020022}\n",
      "{'loss': 1.1056, 'learning_rate': 4.4000000000000006e-05, 'grad_norm': 0.7890625, 'epoch': 0.03533271641288803}\n",
      "{'loss': 1.1576, 'learning_rate': 4.385714285714286e-05, 'grad_norm': 0.8203125, 'epoch': 0.03617397156557584}\n",
      "{'loss': 1.211, 'learning_rate': 4.371428571428572e-05, 'grad_norm': 0.7421875, 'epoch': 0.03701522671826365}\n",
      "{'loss': 1.1244, 'learning_rate': 4.3571428571428576e-05, 'grad_norm': 0.71875, 'epoch': 0.03785648187095146}\n",
      "{'loss': 1.1462, 'learning_rate': 4.342857142857143e-05, 'grad_norm': 0.8359375, 'epoch': 0.03869773702363927}\n",
      "{'loss': 1.246, 'learning_rate': 4.328571428571429e-05, 'grad_norm': 0.7421875, 'epoch': 0.03953899217632708}\n",
      "{'loss': 1.0287, 'learning_rate': 4.314285714285715e-05, 'grad_norm': 0.67578125, 'epoch': 0.04038024732901489}\n",
      "{'loss': 1.1174, 'learning_rate': 4.3e-05, 'grad_norm': 0.765625, 'epoch': 0.0412215024817027}\n",
      "{'loss': 1.1939, 'learning_rate': 4.2857142857142856e-05, 'grad_norm': 0.5625, 'epoch': 0.04206275763439051}\n",
      "Saving model checkpoint to /home/ubuntu/environment/ml/SY/qwen/checkpoint-500\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "[2025-11-08 23:26:32.430: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint adapter_shards began\n",
      "[2025-11-08 23:26:32.614: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint adapter_shards completed\n",
      "[2025-11-08 23:26:32.615: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 1.004, 'learning_rate': 4.271428571428572e-05, 'grad_norm': 0.7265625, 'epoch': 0.04290401278707832}\n",
      "{'loss': 1.1466, 'learning_rate': 4.257142857142857e-05, 'grad_norm': 0.73046875, 'epoch': 0.04374526793976613}\n",
      "{'loss': 1.0987, 'learning_rate': 4.242857142857143e-05, 'grad_norm': 0.7734375, 'epoch': 0.04458652309245394}\n",
      "{'loss': 1.1011, 'learning_rate': 4.228571428571429e-05, 'grad_norm': 0.71875, 'epoch': 0.04542777824514175}\n",
      "{'loss': 1.0996, 'learning_rate': 4.214285714285714e-05, 'grad_norm': 0.6953125, 'epoch': 0.04626903339782956}\n",
      "{'loss': 1.1862, 'learning_rate': 4.2e-05, 'grad_norm': 0.703125, 'epoch': 0.047110288550517375}\n",
      "{'loss': 1.2303, 'learning_rate': 4.185714285714286e-05, 'grad_norm': 0.66796875, 'epoch': 0.04795154370320518}\n",
      "{'loss': 1.0187, 'learning_rate': 4.1714285714285714e-05, 'grad_norm': 0.6875, 'epoch': 0.048792798855892994}\n",
      "{'loss': 1.0489, 'learning_rate': 4.1571428571428575e-05, 'grad_norm': 0.75, 'epoch': 0.0496340540085808}\n",
      "{'loss': 0.9717, 'learning_rate': 4.1428571428571437e-05, 'grad_norm': 0.72265625, 'epoch': 0.05047530916126861}\n",
      "{'loss': 1.1029, 'learning_rate': 4.128571428571429e-05, 'grad_norm': 0.7109375, 'epoch': 0.051316564313956425}\n",
      "{'loss': 1.1674, 'learning_rate': 4.1142857142857146e-05, 'grad_norm': 0.76171875, 'epoch': 0.05215781946664423}\n",
      "{'loss': 1.1385, 'learning_rate': 4.1e-05, 'grad_norm': 0.7578125, 'epoch': 0.052999074619332044}\n",
      "{'loss': 1.1228, 'learning_rate': 4.085714285714286e-05, 'grad_norm': 0.6953125, 'epoch': 0.05384032977201986}\n",
      "{'loss': 1.2216, 'learning_rate': 4.0714285714285717e-05, 'grad_norm': 0.62890625, 'epoch': 0.05468158492470766}\n",
      "{'loss': 1.1288, 'learning_rate': 4.057142857142857e-05, 'grad_norm': 0.71484375, 'epoch': 0.055522840077395476}\n",
      "{'loss': 1.0883, 'learning_rate': 4.042857142857143e-05, 'grad_norm': 0.77734375, 'epoch': 0.05636409523008328}\n",
      "{'loss': 1.1352, 'learning_rate': 4.028571428571429e-05, 'grad_norm': 0.8125, 'epoch': 0.057205350382771095}\n",
      "{'loss': 1.0456, 'learning_rate': 4.014285714285714e-05, 'grad_norm': 0.703125, 'epoch': 0.05804660553545891}\n",
      "{'loss': 1.1571, 'learning_rate': 4e-05, 'grad_norm': 0.74609375, 'epoch': 0.05888786068814671}\n",
      "{'loss': 1.1733, 'learning_rate': 3.985714285714286e-05, 'grad_norm': 0.70703125, 'epoch': 0.059729115840834526}\n",
      "{'loss': 1.2214, 'learning_rate': 3.971428571428571e-05, 'grad_norm': 0.828125, 'epoch': 0.06057037099352233}\n",
      "{'loss': 1.1609, 'learning_rate': 3.9571428571428574e-05, 'grad_norm': 0.640625, 'epoch': 0.061411626146210145}\n",
      "{'loss': 1.1447, 'learning_rate': 3.942857142857143e-05, 'grad_norm': 0.73046875, 'epoch': 0.06225288129889796}\n",
      "{'loss': 1.0371, 'learning_rate': 3.928571428571429e-05, 'grad_norm': 0.80859375, 'epoch': 0.06309413645158576}\n",
      "{'loss': 1.204, 'learning_rate': 3.9142857142857145e-05, 'grad_norm': 0.81640625, 'epoch': 0.06393539160427357}\n",
      "{'loss': 1.0389, 'learning_rate': 3.9000000000000006e-05, 'grad_norm': 0.75390625, 'epoch': 0.06477664675696139}\n",
      "{'loss': 1.0856, 'learning_rate': 3.885714285714286e-05, 'grad_norm': 0.80078125, 'epoch': 0.0656179019096492}\n",
      "{'loss': 1.1984, 'learning_rate': 3.8714285714285715e-05, 'grad_norm': 0.8125, 'epoch': 0.066459157062337}\n",
      "{'loss': 1.0232, 'learning_rate': 3.857142857142858e-05, 'grad_norm': 0.6640625, 'epoch': 0.06730041221502482}\n",
      "{'loss': 1.1935, 'learning_rate': 3.842857142857143e-05, 'grad_norm': 0.76953125, 'epoch': 0.06814166736771263}\n",
      "{'loss': 1.1318, 'learning_rate': 3.8285714285714286e-05, 'grad_norm': 0.7578125, 'epoch': 0.06898292252040043}\n",
      "{'loss': 1.0552, 'learning_rate': 3.814285714285715e-05, 'grad_norm': 0.703125, 'epoch': 0.06982417767308825}\n",
      "{'loss': 1.1392, 'learning_rate': 3.8e-05, 'grad_norm': 0.73046875, 'epoch': 0.07066543282577606}\n",
      "{'loss': 0.9637, 'learning_rate': 3.785714285714286e-05, 'grad_norm': 0.70703125, 'epoch': 0.07150668797846386}\n",
      "{'loss': 0.9764, 'learning_rate': 3.771428571428572e-05, 'grad_norm': 0.71875, 'epoch': 0.07234794313115168}\n",
      "{'loss': 1.0071, 'learning_rate': 3.757142857142857e-05, 'grad_norm': 0.8046875, 'epoch': 0.07318919828383949}\n",
      "{'loss': 0.9832, 'learning_rate': 3.742857142857143e-05, 'grad_norm': 0.67578125, 'epoch': 0.0740304534365273}\n",
      "{'loss': 1.0404, 'learning_rate': 3.728571428571428e-05, 'grad_norm': 0.77734375, 'epoch': 0.0748717085892151}\n",
      "{'loss': 1.0437, 'learning_rate': 3.7142857142857143e-05, 'grad_norm': 0.734375, 'epoch': 0.07571296374190292}\n",
      "{'loss': 1.0122, 'learning_rate': 3.7e-05, 'grad_norm': 0.80078125, 'epoch': 0.07655421889459073}\n",
      "{'loss': 1.1229, 'learning_rate': 3.685714285714286e-05, 'grad_norm': 0.80078125, 'epoch': 0.07739547404727853}\n",
      "{'loss': 1.0721, 'learning_rate': 3.671428571428572e-05, 'grad_norm': 0.71484375, 'epoch': 0.07823672919996635}\n",
      "{'loss': 1.0213, 'learning_rate': 3.6571428571428576e-05, 'grad_norm': 0.77734375, 'epoch': 0.07907798435265416}\n",
      "{'loss': 0.9741, 'learning_rate': 3.642857142857143e-05, 'grad_norm': 0.73046875, 'epoch': 0.07991923950534197}\n",
      "{'loss': 1.0462, 'learning_rate': 3.628571428571429e-05, 'grad_norm': 1.15625, 'epoch': 0.08076049465802979}\n",
      "{'loss': 1.1392, 'learning_rate': 3.6142857142857146e-05, 'grad_norm': 0.765625, 'epoch': 0.08160174981071759}\n",
      "{'loss': 1.1929, 'learning_rate': 3.6e-05, 'grad_norm': 0.6796875, 'epoch': 0.0824430049634054}\n",
      "{'loss': 1.0521, 'learning_rate': 3.585714285714286e-05, 'grad_norm': 0.72265625, 'epoch': 0.08328426011609322}\n",
      "{'loss': 1.1737, 'learning_rate': 3.571428571428572e-05, 'grad_norm': 0.73828125, 'epoch': 0.08412551526878102}\n",
      "Saving model checkpoint to /home/ubuntu/environment/ml/SY/qwen/checkpoint-1000\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "[2025-11-08 23:35:04.674: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint adapter_shards began\n",
      "[2025-11-08 23:35:04.840: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint adapter_shards completed\n",
      "[2025-11-08 23:35:04.841: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 1.1967, 'learning_rate': 3.557142857142857e-05, 'grad_norm': 0.75, 'epoch': 0.08496677042146883}\n",
      "{'loss': 1.0645, 'learning_rate': 3.5428571428571426e-05, 'grad_norm': 0.62109375, 'epoch': 0.08580802557415664}\n",
      "{'loss': 0.9349, 'learning_rate': 3.528571428571429e-05, 'grad_norm': 0.7265625, 'epoch': 0.08664928072684445}\n",
      "{'loss': 1.2039, 'learning_rate': 3.514285714285714e-05, 'grad_norm': 0.78125, 'epoch': 0.08749053587953226}\n",
      "{'loss': 0.9581, 'learning_rate': 3.5e-05, 'grad_norm': 0.69921875, 'epoch': 0.08833179103222007}\n",
      "{'loss': 0.869, 'learning_rate': 3.485714285714286e-05, 'grad_norm': 0.76953125, 'epoch': 0.08917304618490789}\n",
      "{'loss': 1.1126, 'learning_rate': 3.471428571428571e-05, 'grad_norm': 0.828125, 'epoch': 0.09001430133759569}\n",
      "{'loss': 1.2431, 'learning_rate': 3.4571428571428574e-05, 'grad_norm': 0.859375, 'epoch': 0.0908555564902835}\n",
      "{'loss': 1.0813, 'learning_rate': 3.442857142857143e-05, 'grad_norm': 0.84375, 'epoch': 0.09169681164297132}\n",
      "{'loss': 0.9878, 'learning_rate': 3.428571428571429e-05, 'grad_norm': 0.890625, 'epoch': 0.09253806679565912}\n",
      "{'loss': 1.1145, 'learning_rate': 3.4142857142857145e-05, 'grad_norm': 0.875, 'epoch': 0.09337932194834693}\n",
      "{'loss': 1.1077, 'learning_rate': 3.4000000000000007e-05, 'grad_norm': 0.81640625, 'epoch': 0.09422057710103475}\n",
      "{'loss': 1.1025, 'learning_rate': 3.385714285714286e-05, 'grad_norm': 0.93359375, 'epoch': 0.09506183225372256}\n",
      "{'loss': 1.0698, 'learning_rate': 3.3714285714285716e-05, 'grad_norm': 1.046875, 'epoch': 0.09590308740641036}\n",
      "{'loss': 1.1794, 'learning_rate': 3.357142857142857e-05, 'grad_norm': 0.71484375, 'epoch': 0.09674434255909817}\n",
      "{'loss': 1.083, 'learning_rate': 3.342857142857143e-05, 'grad_norm': 0.70703125, 'epoch': 0.09758559771178599}\n",
      "{'loss': 1.0662, 'learning_rate': 3.3285714285714286e-05, 'grad_norm': 0.78125, 'epoch': 0.0984268528644738}\n",
      "{'loss': 1.0943, 'learning_rate': 3.314285714285714e-05, 'grad_norm': 0.71484375, 'epoch': 0.0992681080171616}\n",
      "{'loss': 1.2621, 'learning_rate': 3.3e-05, 'grad_norm': 0.70703125, 'epoch': 0.10010936316984942}\n",
      "{'loss': 0.9955, 'learning_rate': 3.285714285714286e-05, 'grad_norm': 0.70703125, 'epoch': 0.10095061832253723}\n",
      "{'loss': 1.1437, 'learning_rate': 3.271428571428571e-05, 'grad_norm': 0.69140625, 'epoch': 0.10179187347522503}\n",
      "{'loss': 1.1002, 'learning_rate': 3.257142857142857e-05, 'grad_norm': 0.84765625, 'epoch': 0.10263312862791285}\n",
      "{'loss': 0.9916, 'learning_rate': 3.242857142857143e-05, 'grad_norm': 0.81640625, 'epoch': 0.10347438378060066}\n",
      "{'loss': 1.1193, 'learning_rate': 3.228571428571428e-05, 'grad_norm': 0.9921875, 'epoch': 0.10431563893328846}\n",
      "{'loss': 1.0079, 'learning_rate': 3.2142857142857144e-05, 'grad_norm': 0.7734375, 'epoch': 0.10515689408597628}\n",
      "{'loss': 1.0374, 'learning_rate': 3.2000000000000005e-05, 'grad_norm': 0.79296875, 'epoch': 0.10599814923866409}\n",
      "{'loss': 1.104, 'learning_rate': 3.185714285714286e-05, 'grad_norm': 0.7109375, 'epoch': 0.1068394043913519}\n",
      "{'loss': 0.9904, 'learning_rate': 3.1714285714285715e-05, 'grad_norm': 0.77734375, 'epoch': 0.10768065954403971}\n",
      "{'loss': 1.0704, 'learning_rate': 3.1571428571428576e-05, 'grad_norm': 0.7578125, 'epoch': 0.10852191469672752}\n",
      "{'loss': 1.0522, 'learning_rate': 3.142857142857143e-05, 'grad_norm': 0.73828125, 'epoch': 0.10936316984941533}\n",
      "{'loss': 1.0803, 'learning_rate': 3.1285714285714285e-05, 'grad_norm': 0.703125, 'epoch': 0.11020442500210313}\n",
      "{'loss': 1.1743, 'learning_rate': 3.114285714285715e-05, 'grad_norm': 0.76171875, 'epoch': 0.11104568015479095}\n",
      "{'loss': 1.1546, 'learning_rate': 3.1e-05, 'grad_norm': 0.765625, 'epoch': 0.11188693530747876}\n",
      "{'loss': 1.2527, 'learning_rate': 3.0857142857142856e-05, 'grad_norm': 0.8203125, 'epoch': 0.11272819046016656}\n",
      "{'loss': 1.1188, 'learning_rate': 3.071428571428572e-05, 'grad_norm': 0.73046875, 'epoch': 0.11356944561285438}\n",
      "{'loss': 1.3068, 'learning_rate': 3.057142857142857e-05, 'grad_norm': 0.7421875, 'epoch': 0.11441070076554219}\n",
      "{'loss': 1.0972, 'learning_rate': 3.042857142857143e-05, 'grad_norm': 0.921875, 'epoch': 0.11525195591823}\n",
      "{'loss': 1.1293, 'learning_rate': 3.0285714285714288e-05, 'grad_norm': 0.76953125, 'epoch': 0.11609321107091781}\n",
      "{'loss': 0.9977, 'learning_rate': 3.0142857142857146e-05, 'grad_norm': 0.671875, 'epoch': 0.11693446622360562}\n",
      "{'loss': 1.1336, 'learning_rate': 3e-05, 'grad_norm': 0.65234375, 'epoch': 0.11777572137629343}\n",
      "{'loss': 1.0636, 'learning_rate': 2.9857142857142862e-05, 'grad_norm': 0.84375, 'epoch': 0.11861697652898125}\n",
      "{'loss': 1.2051, 'learning_rate': 2.9714285714285717e-05, 'grad_norm': 0.72265625, 'epoch': 0.11945823168166905}\n",
      "{'loss': 1.2251, 'learning_rate': 2.957142857142857e-05, 'grad_norm': 0.765625, 'epoch': 0.12029948683435686}\n",
      "{'loss': 1.1047, 'learning_rate': 2.9428571428571426e-05, 'grad_norm': 0.83984375, 'epoch': 0.12114074198704466}\n",
      "{'loss': 1.0996, 'learning_rate': 2.9285714285714288e-05, 'grad_norm': 0.640625, 'epoch': 0.12198199713973248}\n",
      "{'loss': 1.0317, 'learning_rate': 2.9142857142857146e-05, 'grad_norm': 0.9453125, 'epoch': 0.12282325229242029}\n",
      "{'loss': 1.1558, 'learning_rate': 2.9e-05, 'grad_norm': 0.71484375, 'epoch': 0.1236645074451081}\n",
      "{'loss': 1.0263, 'learning_rate': 2.885714285714286e-05, 'grad_norm': 0.7421875, 'epoch': 0.12450576259779592}\n",
      "{'loss': 1.177, 'learning_rate': 2.8714285714285716e-05, 'grad_norm': 0.71484375, 'epoch': 0.1253470177504837}\n",
      "{'loss': 1.1012, 'learning_rate': 2.857142857142857e-05, 'grad_norm': 0.73046875, 'epoch': 0.12618827290317153}\n",
      "Saving model checkpoint to /home/ubuntu/environment/ml/SY/qwen/checkpoint-1500\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "[2025-11-08 23:43:34.075: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint adapter_shards began\n",
      "[2025-11-08 23:43:34.247: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint adapter_shards completed\n",
      "[2025-11-08 23:43:34.248: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 1.1981, 'learning_rate': 2.8428571428571432e-05, 'grad_norm': 0.70703125, 'epoch': 0.12702952805585935}\n",
      "{'loss': 0.9471, 'learning_rate': 2.8285714285714287e-05, 'grad_norm': 0.71484375, 'epoch': 0.12787078320854714}\n",
      "{'loss': 1.0192, 'learning_rate': 2.814285714285714e-05, 'grad_norm': 0.78125, 'epoch': 0.12871203836123496}\n",
      "{'loss': 1.2598, 'learning_rate': 2.8000000000000003e-05, 'grad_norm': 0.9375, 'epoch': 0.12955329351392278}\n",
      "{'loss': 1.0518, 'learning_rate': 2.785714285714286e-05, 'grad_norm': 0.69921875, 'epoch': 0.13039454866661057}\n",
      "{'loss': 1.0322, 'learning_rate': 2.7714285714285716e-05, 'grad_norm': 0.68359375, 'epoch': 0.1312358038192984}\n",
      "{'loss': 0.8856, 'learning_rate': 2.757142857142857e-05, 'grad_norm': 0.70703125, 'epoch': 0.1320770589719862}\n",
      "{'loss': 1.1104, 'learning_rate': 2.742857142857143e-05, 'grad_norm': 0.75390625, 'epoch': 0.132918314124674}\n",
      "{'loss': 1.0556, 'learning_rate': 2.7285714285714286e-05, 'grad_norm': 0.87109375, 'epoch': 0.13375956927736182}\n",
      "{'loss': 1.1514, 'learning_rate': 2.714285714285714e-05, 'grad_norm': 0.7734375, 'epoch': 0.13460082443004964}\n",
      "{'loss': 0.9652, 'learning_rate': 2.7000000000000002e-05, 'grad_norm': 0.6953125, 'epoch': 0.13544207958273743}\n",
      "{'loss': 1.1557, 'learning_rate': 2.6857142857142857e-05, 'grad_norm': 1.1328125, 'epoch': 0.13628333473542525}\n",
      "{'loss': 0.9116, 'learning_rate': 2.6714285714285715e-05, 'grad_norm': 0.78125, 'epoch': 0.13712458988811307}\n",
      "{'loss': 0.9587, 'learning_rate': 2.6571428571428576e-05, 'grad_norm': 0.65625, 'epoch': 0.13796584504080087}\n",
      "{'loss': 1.0525, 'learning_rate': 2.642857142857143e-05, 'grad_norm': 0.7578125, 'epoch': 0.13880710019348869}\n",
      "{'loss': 1.1749, 'learning_rate': 2.6285714285714286e-05, 'grad_norm': 0.84765625, 'epoch': 0.1396483553461765}\n",
      "{'loss': 0.8889, 'learning_rate': 2.6142857142857147e-05, 'grad_norm': 1.1171875, 'epoch': 0.1404896104988643}\n",
      "{'loss': 0.9938, 'learning_rate': 2.6000000000000002e-05, 'grad_norm': 0.828125, 'epoch': 0.14133086565155212}\n",
      "{'loss': 0.992, 'learning_rate': 2.5857142857142856e-05, 'grad_norm': 0.79296875, 'epoch': 0.14217212080423994}\n",
      "{'loss': 1.1182, 'learning_rate': 2.5714285714285714e-05, 'grad_norm': 0.92578125, 'epoch': 0.14301337595692773}\n",
      "{'loss': 0.981, 'learning_rate': 2.5571428571428572e-05, 'grad_norm': 0.88671875, 'epoch': 0.14385463110961555}\n",
      "{'loss': 1.1062, 'learning_rate': 2.542857142857143e-05, 'grad_norm': 0.984375, 'epoch': 0.14469588626230337}\n",
      "{'loss': 1.0795, 'learning_rate': 2.5285714285714285e-05, 'grad_norm': 0.81640625, 'epoch': 0.14553714141499116}\n",
      "{'loss': 1.0747, 'learning_rate': 2.5142857142857147e-05, 'grad_norm': 0.83984375, 'epoch': 0.14637839656767898}\n",
      "{'loss': 1.0078, 'learning_rate': 2.5e-05, 'grad_norm': 0.69921875, 'epoch': 0.1472196517203668}\n",
      "{'loss': 1.0082, 'learning_rate': 2.485714285714286e-05, 'grad_norm': 0.80078125, 'epoch': 0.1480609068730546}\n",
      "{'loss': 1.1975, 'learning_rate': 2.4714285714285714e-05, 'grad_norm': 0.921875, 'epoch': 0.1489021620257424}\n",
      "{'loss': 1.0082, 'learning_rate': 2.4571428571428572e-05, 'grad_norm': 0.80078125, 'epoch': 0.1497434171784302}\n",
      "{'loss': 1.1287, 'learning_rate': 2.442857142857143e-05, 'grad_norm': 0.79296875, 'epoch': 0.15058467233111802}\n",
      "{'loss': 1.0235, 'learning_rate': 2.4285714285714288e-05, 'grad_norm': 0.828125, 'epoch': 0.15142592748380584}\n",
      "{'loss': 1.0787, 'learning_rate': 2.4142857142857146e-05, 'grad_norm': 0.8046875, 'epoch': 0.15226718263649364}\n",
      "{'loss': 0.9646, 'learning_rate': 2.4e-05, 'grad_norm': 0.859375, 'epoch': 0.15310843778918146}\n",
      "{'loss': 1.0391, 'learning_rate': 2.385714285714286e-05, 'grad_norm': 0.7109375, 'epoch': 0.15394969294186928}\n",
      "{'loss': 1.0758, 'learning_rate': 2.3714285714285717e-05, 'grad_norm': 0.86328125, 'epoch': 0.15479094809455707}\n",
      "{'loss': 0.9129, 'learning_rate': 2.357142857142857e-05, 'grad_norm': 0.796875, 'epoch': 0.1556322032472449}\n",
      "{'loss': 1.0421, 'learning_rate': 2.342857142857143e-05, 'grad_norm': 0.6796875, 'epoch': 0.1564734583999327}\n",
      "{'loss': 1.0619, 'learning_rate': 2.3285714285714287e-05, 'grad_norm': 0.875, 'epoch': 0.1573147135526205}\n",
      "{'loss': 1.1477, 'learning_rate': 2.3142857142857145e-05, 'grad_norm': 0.80078125, 'epoch': 0.15815596870530832}\n",
      "{'loss': 1.1239, 'learning_rate': 2.3000000000000003e-05, 'grad_norm': 0.921875, 'epoch': 0.15899722385799614}\n",
      "{'loss': 1.0835, 'learning_rate': 2.2857142857142858e-05, 'grad_norm': 0.796875, 'epoch': 0.15983847901068393}\n",
      "{'loss': 1.1657, 'learning_rate': 2.2714285714285716e-05, 'grad_norm': 0.91015625, 'epoch': 0.16067973416337175}\n",
      "{'loss': 1.0708, 'learning_rate': 2.257142857142857e-05, 'grad_norm': 1.1171875, 'epoch': 0.16152098931605957}\n",
      "{'loss': 1.1741, 'learning_rate': 2.242857142857143e-05, 'grad_norm': 0.8203125, 'epoch': 0.16236224446874736}\n",
      "{'loss': 0.8616, 'learning_rate': 2.2285714285714287e-05, 'grad_norm': 0.83984375, 'epoch': 0.16320349962143518}\n",
      "{'loss': 0.9429, 'learning_rate': 2.214285714285714e-05, 'grad_norm': 0.79296875, 'epoch': 0.164044754774123}\n",
      "{'loss': 1.0656, 'learning_rate': 2.2000000000000003e-05, 'grad_norm': 0.7265625, 'epoch': 0.1648860099268108}\n",
      "{'loss': 1.1005, 'learning_rate': 2.185714285714286e-05, 'grad_norm': 0.859375, 'epoch': 0.16572726507949861}\n",
      "{'loss': 1.0549, 'learning_rate': 2.1714285714285715e-05, 'grad_norm': 0.75390625, 'epoch': 0.16656852023218643}\n",
      "{'loss': 1.0146, 'learning_rate': 2.1571428571428574e-05, 'grad_norm': 0.89453125, 'epoch': 0.16740977538487423}\n",
      "{'loss': 0.9105, 'learning_rate': 2.1428571428571428e-05, 'grad_norm': 0.84765625, 'epoch': 0.16825103053756205}\n",
      "Saving model checkpoint to /home/ubuntu/environment/ml/SY/qwen/checkpoint-2000\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "[2025-11-08 23:52:09.505: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint adapter_shards began\n",
      "[2025-11-08 23:52:09.684: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint adapter_shards completed\n",
      "[2025-11-08 23:52:09.685: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 1.0034, 'learning_rate': 2.1285714285714286e-05, 'grad_norm': 0.75390625, 'epoch': 0.16909228569024987}\n",
      "{'loss': 0.8916, 'learning_rate': 2.1142857142857144e-05, 'grad_norm': 0.68359375, 'epoch': 0.16993354084293766}\n",
      "{'loss': 0.9478, 'learning_rate': 2.1e-05, 'grad_norm': 0.78125, 'epoch': 0.17077479599562548}\n",
      "{'loss': 1.1341, 'learning_rate': 2.0857142857142857e-05, 'grad_norm': 0.86328125, 'epoch': 0.17161605114831327}\n",
      "{'loss': 0.9452, 'learning_rate': 2.0714285714285718e-05, 'grad_norm': 0.80859375, 'epoch': 0.1724573063010011}\n",
      "{'loss': 1.1902, 'learning_rate': 2.0571428571428573e-05, 'grad_norm': 0.71875, 'epoch': 0.1732985614536889}\n",
      "{'loss': 0.9525, 'learning_rate': 2.042857142857143e-05, 'grad_norm': 0.7734375, 'epoch': 0.1741398166063767}\n",
      "{'loss': 0.9821, 'learning_rate': 2.0285714285714286e-05, 'grad_norm': 0.87109375, 'epoch': 0.17498107175906452}\n",
      "{'loss': 1.0721, 'learning_rate': 2.0142857142857144e-05, 'grad_norm': 0.81640625, 'epoch': 0.17582232691175234}\n",
      "{'loss': 1.0926, 'learning_rate': 2e-05, 'grad_norm': 0.7421875, 'epoch': 0.17666358206444013}\n",
      "{'loss': 1.0561, 'learning_rate': 1.9857142857142856e-05, 'grad_norm': 0.80859375, 'epoch': 0.17750483721712795}\n",
      "{'loss': 1.0392, 'learning_rate': 1.9714285714285714e-05, 'grad_norm': 0.80859375, 'epoch': 0.17834609236981577}\n",
      "{'loss': 0.9545, 'learning_rate': 1.9571428571428572e-05, 'grad_norm': 0.78125, 'epoch': 0.17918734752250357}\n",
      "{'loss': 0.9989, 'learning_rate': 1.942857142857143e-05, 'grad_norm': 0.84375, 'epoch': 0.18002860267519138}\n",
      "{'loss': 1.0412, 'learning_rate': 1.928571428571429e-05, 'grad_norm': 0.9375, 'epoch': 0.1808698578278792}\n",
      "{'loss': 1.1387, 'learning_rate': 1.9142857142857143e-05, 'grad_norm': 0.9140625, 'epoch': 0.181711112980567}\n",
      "{'loss': 1.1323, 'learning_rate': 1.9e-05, 'grad_norm': 0.7421875, 'epoch': 0.18255236813325482}\n",
      "{'loss': 0.9663, 'learning_rate': 1.885714285714286e-05, 'grad_norm': 0.78125, 'epoch': 0.18339362328594264}\n",
      "{'loss': 1.1061, 'learning_rate': 1.8714285714285714e-05, 'grad_norm': 0.7890625, 'epoch': 0.18423487843863043}\n",
      "{'loss': 1.0915, 'learning_rate': 1.8571428571428572e-05, 'grad_norm': 0.8984375, 'epoch': 0.18507613359131825}\n",
      "{'loss': 1.1258, 'learning_rate': 1.842857142857143e-05, 'grad_norm': 0.7109375, 'epoch': 0.18591738874400607}\n",
      "{'loss': 0.9459, 'learning_rate': 1.8285714285714288e-05, 'grad_norm': 0.78125, 'epoch': 0.18675864389669386}\n",
      "{'loss': 1.0721, 'learning_rate': 1.8142857142857146e-05, 'grad_norm': 0.85546875, 'epoch': 0.18759989904938168}\n",
      "{'loss': 1.1075, 'learning_rate': 1.8e-05, 'grad_norm': 0.79296875, 'epoch': 0.1884411542020695}\n",
      "{'loss': 1.0949, 'learning_rate': 1.785714285714286e-05, 'grad_norm': 0.890625, 'epoch': 0.1892824093547573}\n",
      "{'loss': 1.0452, 'learning_rate': 1.7714285714285713e-05, 'grad_norm': 0.765625, 'epoch': 0.1901236645074451}\n",
      "{'loss': 1.0892, 'learning_rate': 1.757142857142857e-05, 'grad_norm': 0.87890625, 'epoch': 0.19096491966013293}\n",
      "{'loss': 1.0841, 'learning_rate': 1.742857142857143e-05, 'grad_norm': 0.9609375, 'epoch': 0.19180617481282072}\n",
      "{'loss': 1.1673, 'learning_rate': 1.7285714285714287e-05, 'grad_norm': 0.8359375, 'epoch': 0.19264742996550854}\n",
      "{'loss': 0.9617, 'learning_rate': 1.7142857142857145e-05, 'grad_norm': 0.86328125, 'epoch': 0.19348868511819634}\n",
      "{'loss': 0.9902, 'learning_rate': 1.7000000000000003e-05, 'grad_norm': 0.828125, 'epoch': 0.19432994027088416}\n",
      "{'loss': 1.0335, 'learning_rate': 1.6857142857142858e-05, 'grad_norm': 0.69140625, 'epoch': 0.19517119542357197}\n",
      "{'loss': 1.1447, 'learning_rate': 1.6714285714285716e-05, 'grad_norm': 0.86328125, 'epoch': 0.19601245057625977}\n",
      "{'loss': 1.0067, 'learning_rate': 1.657142857142857e-05, 'grad_norm': 0.87109375, 'epoch': 0.1968537057289476}\n",
      "{'loss': 1.0936, 'learning_rate': 1.642857142857143e-05, 'grad_norm': 0.83984375, 'epoch': 0.1976949608816354}\n",
      "{'loss': 1.0101, 'learning_rate': 1.6285714285714287e-05, 'grad_norm': 0.625, 'epoch': 0.1985362160343232}\n",
      "{'loss': 1.0968, 'learning_rate': 1.614285714285714e-05, 'grad_norm': 0.859375, 'epoch': 0.19937747118701102}\n",
      "{'loss': 1.0108, 'learning_rate': 1.6000000000000003e-05, 'grad_norm': 0.76953125, 'epoch': 0.20021872633969884}\n",
      "{'loss': 0.9986, 'learning_rate': 1.5857142857142857e-05, 'grad_norm': 0.7734375, 'epoch': 0.20105998149238663}\n",
      "{'loss': 1.0228, 'learning_rate': 1.5714285714285715e-05, 'grad_norm': 0.85546875, 'epoch': 0.20190123664507445}\n",
      "{'loss': 0.9713, 'learning_rate': 1.5571428571428573e-05, 'grad_norm': 0.8359375, 'epoch': 0.20274249179776227}\n",
      "{'loss': 1.0674, 'learning_rate': 1.5428571428571428e-05, 'grad_norm': 0.84765625, 'epoch': 0.20358374695045006}\n",
      "{'loss': 1.0983, 'learning_rate': 1.5285714285714286e-05, 'grad_norm': 0.77734375, 'epoch': 0.20442500210313788}\n",
      "{'loss': 1.0444, 'learning_rate': 1.5142857142857144e-05, 'grad_norm': 0.87890625, 'epoch': 0.2052662572558257}\n",
      "{'loss': 1.1505, 'learning_rate': 1.5e-05, 'grad_norm': 0.9375, 'epoch': 0.2061075124085135}\n",
      "{'loss': 1.1746, 'learning_rate': 1.4857142857142858e-05, 'grad_norm': 0.94140625, 'epoch': 0.2069487675612013}\n",
      "{'loss': 1.016, 'learning_rate': 1.4714285714285713e-05, 'grad_norm': 0.87109375, 'epoch': 0.20779002271388913}\n",
      "{'loss': 1.1363, 'learning_rate': 1.4571428571428573e-05, 'grad_norm': 0.765625, 'epoch': 0.20863127786657693}\n",
      "{'loss': 1.0411, 'learning_rate': 1.442857142857143e-05, 'grad_norm': 0.89453125, 'epoch': 0.20947253301926475}\n",
      "{'loss': 1.1439, 'learning_rate': 1.4285714285714285e-05, 'grad_norm': 0.734375, 'epoch': 0.21031378817195256}\n",
      "Saving model checkpoint to /home/ubuntu/environment/ml/SY/qwen/checkpoint-2500\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "[2025-11-09 00:00:36.864: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint adapter_shards began\n",
      "[2025-11-09 00:00:37.044: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint adapter_shards completed\n",
      "[2025-11-09 00:00:37.045: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 0.934, 'learning_rate': 1.4142857142857143e-05, 'grad_norm': 0.83984375, 'epoch': 0.21115504332464036}\n",
      "{'loss': 1.001, 'learning_rate': 1.4000000000000001e-05, 'grad_norm': 0.7734375, 'epoch': 0.21199629847732818}\n",
      "{'loss': 1.0873, 'learning_rate': 1.3857142857142858e-05, 'grad_norm': 0.80078125, 'epoch': 0.212837553630016}\n",
      "{'loss': 1.0788, 'learning_rate': 1.3714285714285716e-05, 'grad_norm': 1.109375, 'epoch': 0.2136788087827038}\n",
      "{'loss': 1.0264, 'learning_rate': 1.357142857142857e-05, 'grad_norm': 0.8125, 'epoch': 0.2145200639353916}\n",
      "{'loss': 1.04, 'learning_rate': 1.3428571428571429e-05, 'grad_norm': 0.90625, 'epoch': 0.21536131908807943}\n",
      "{'loss': 1.1396, 'learning_rate': 1.3285714285714288e-05, 'grad_norm': 0.78515625, 'epoch': 0.21620257424076722}\n",
      "{'loss': 0.9154, 'learning_rate': 1.3142857142857143e-05, 'grad_norm': 0.796875, 'epoch': 0.21704382939345504}\n",
      "{'loss': 0.994, 'learning_rate': 1.3000000000000001e-05, 'grad_norm': 0.89453125, 'epoch': 0.21788508454614283}\n",
      "{'loss': 1.1216, 'learning_rate': 1.2857142857142857e-05, 'grad_norm': 0.72265625, 'epoch': 0.21872633969883065}\n",
      "{'loss': 1.1995, 'learning_rate': 1.2714285714285715e-05, 'grad_norm': 0.82421875, 'epoch': 0.21956759485151847}\n",
      "{'loss': 1.1014, 'learning_rate': 1.2571428571428573e-05, 'grad_norm': 0.84375, 'epoch': 0.22040885000420626}\n",
      "{'loss': 0.934, 'learning_rate': 1.242857142857143e-05, 'grad_norm': 0.765625, 'epoch': 0.22125010515689408}\n",
      "{'loss': 0.9593, 'learning_rate': 1.2285714285714286e-05, 'grad_norm': 0.7734375, 'epoch': 0.2220913603095819}\n",
      "{'loss': 0.9881, 'learning_rate': 1.2142857142857144e-05, 'grad_norm': 0.7890625, 'epoch': 0.2229326154622697}\n",
      "{'loss': 0.9605, 'learning_rate': 1.2e-05, 'grad_norm': 0.921875, 'epoch': 0.22377387061495752}\n",
      "{'loss': 1.0646, 'learning_rate': 1.1857142857142858e-05, 'grad_norm': 0.859375, 'epoch': 0.22461512576764533}\n",
      "{'loss': 0.9467, 'learning_rate': 1.1714285714285715e-05, 'grad_norm': 0.8203125, 'epoch': 0.22545638092033313}\n",
      "{'loss': 1.0796, 'learning_rate': 1.1571428571428573e-05, 'grad_norm': 0.81640625, 'epoch': 0.22629763607302095}\n",
      "{'loss': 0.8991, 'learning_rate': 1.1428571428571429e-05, 'grad_norm': 0.80859375, 'epoch': 0.22713889122570877}\n",
      "{'loss': 1.039, 'learning_rate': 1.1285714285714285e-05, 'grad_norm': 0.84765625, 'epoch': 0.22798014637839656}\n",
      "{'loss': 1.0283, 'learning_rate': 1.1142857142857143e-05, 'grad_norm': 0.89453125, 'epoch': 0.22882140153108438}\n",
      "{'loss': 1.1315, 'learning_rate': 1.1000000000000001e-05, 'grad_norm': 0.90234375, 'epoch': 0.2296626566837722}\n",
      "{'loss': 1.1256, 'learning_rate': 1.0857142857142858e-05, 'grad_norm': 0.8359375, 'epoch': 0.23050391183646}\n",
      "{'loss': 0.9988, 'learning_rate': 1.0714285714285714e-05, 'grad_norm': 0.83203125, 'epoch': 0.2313451669891478}\n",
      "{'loss': 1.1208, 'learning_rate': 1.0571428571428572e-05, 'grad_norm': 0.89453125, 'epoch': 0.23218642214183563}\n",
      "{'loss': 1.2025, 'learning_rate': 1.0428571428571428e-05, 'grad_norm': 0.875, 'epoch': 0.23302767729452342}\n",
      "{'loss': 1.1709, 'learning_rate': 1.0285714285714286e-05, 'grad_norm': 0.80078125, 'epoch': 0.23386893244721124}\n",
      "{'loss': 0.9155, 'learning_rate': 1.0142857142857143e-05, 'grad_norm': 0.7578125, 'epoch': 0.23471018759989906}\n",
      "{'loss': 1.1562, 'learning_rate': 1e-05, 'grad_norm': 0.7265625, 'epoch': 0.23555144275258685}\n",
      "{'loss': 0.9866, 'learning_rate': 9.857142857142857e-06, 'grad_norm': 0.8125, 'epoch': 0.23639269790527467}\n",
      "{'loss': 1.1665, 'learning_rate': 9.714285714285715e-06, 'grad_norm': 0.83203125, 'epoch': 0.2372339530579625}\n",
      "{'loss': 0.9863, 'learning_rate': 9.571428571428572e-06, 'grad_norm': 0.875, 'epoch': 0.23807520821065029}\n",
      "{'loss': 1.0158, 'learning_rate': 9.42857142857143e-06, 'grad_norm': 0.78515625, 'epoch': 0.2389164633633381}\n",
      "{'loss': 0.9235, 'learning_rate': 9.285714285714286e-06, 'grad_norm': 0.77734375, 'epoch': 0.2397577185160259}\n",
      "{'loss': 0.9744, 'learning_rate': 9.142857142857144e-06, 'grad_norm': 1.09375, 'epoch': 0.24059897366871372}\n",
      "{'loss': 1.0496, 'learning_rate': 9e-06, 'grad_norm': 0.9140625, 'epoch': 0.24144022882140154}\n",
      "{'loss': 1.0642, 'learning_rate': 8.857142857142857e-06, 'grad_norm': 0.80078125, 'epoch': 0.24228148397408933}\n",
      "{'loss': 0.9635, 'learning_rate': 8.714285714285715e-06, 'grad_norm': 0.85546875, 'epoch': 0.24312273912677715}\n",
      "{'loss': 1.0449, 'learning_rate': 8.571428571428573e-06, 'grad_norm': 1.5234375, 'epoch': 0.24396399427946497}\n",
      "{'loss': 1.0265, 'learning_rate': 8.428571428571429e-06, 'grad_norm': 0.9765625, 'epoch': 0.24480524943215276}\n",
      "{'loss': 0.9655, 'learning_rate': 8.285714285714285e-06, 'grad_norm': 0.8828125, 'epoch': 0.24564650458484058}\n",
      "{'loss': 0.9977, 'learning_rate': 8.142857142857143e-06, 'grad_norm': 0.7109375, 'epoch': 0.2464877597375284}\n",
      "{'loss': 1.0147, 'learning_rate': 8.000000000000001e-06, 'grad_norm': 0.83984375, 'epoch': 0.2473290148902162}\n",
      "{'loss': 1.0267, 'learning_rate': 7.857142857142858e-06, 'grad_norm': 0.7421875, 'epoch': 0.248170270042904}\n",
      "{'loss': 1.0337, 'learning_rate': 7.714285714285714e-06, 'grad_norm': 0.796875, 'epoch': 0.24901152519559183}\n",
      "{'loss': 1.0508, 'learning_rate': 7.571428571428572e-06, 'grad_norm': 0.8671875, 'epoch': 0.24985278034827962}\n",
      "{'loss': 0.9152, 'learning_rate': 7.428571428571429e-06, 'grad_norm': 0.73828125, 'epoch': 0.2506940355009674}\n",
      "{'loss': 1.0744, 'learning_rate': 7.285714285714286e-06, 'grad_norm': 0.890625, 'epoch': 0.25153529065365526}\n",
      "{'loss': 1.0645, 'learning_rate': 7.142857142857143e-06, 'grad_norm': 0.921875, 'epoch': 0.25237654580634306}\n",
      "Saving model checkpoint to /home/ubuntu/environment/ml/SY/qwen/checkpoint-3000\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "[2025-11-09 00:09:04.747: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint adapter_shards began\n",
      "[2025-11-09 00:09:04.924: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint adapter_shards completed\n",
      "[2025-11-09 00:09:04.925: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "{'loss': 1.0986, 'learning_rate': 7.000000000000001e-06, 'grad_norm': 0.73046875, 'epoch': 0.25321780095903085}\n",
      "{'loss': 1.1005, 'learning_rate': 6.857142857142858e-06, 'grad_norm': 0.83984375, 'epoch': 0.2540590561117187}\n",
      "{'loss': 0.904, 'learning_rate': 6.714285714285714e-06, 'grad_norm': 0.73046875, 'epoch': 0.2549003112644065}\n",
      "{'loss': 0.9002, 'learning_rate': 6.5714285714285714e-06, 'grad_norm': 0.80078125, 'epoch': 0.2557415664170943}\n",
      "{'loss': 1.1046, 'learning_rate': 6.428571428571429e-06, 'grad_norm': 0.9375, 'epoch': 0.2565828215697821}\n",
      "{'loss': 0.85, 'learning_rate': 6.285714285714287e-06, 'grad_norm': 0.859375, 'epoch': 0.2574240767224699}\n",
      "{'loss': 1.0584, 'learning_rate': 6.142857142857143e-06, 'grad_norm': 0.82421875, 'epoch': 0.2582653318751577}\n",
      "{'loss': 1.0298, 'learning_rate': 6e-06, 'grad_norm': 0.92578125, 'epoch': 0.25910658702784556}\n",
      "{'loss': 0.9577, 'learning_rate': 5.857142857142857e-06, 'grad_norm': 0.8671875, 'epoch': 0.25994784218053335}\n",
      "{'loss': 1.0526, 'learning_rate': 5.7142857142857145e-06, 'grad_norm': 0.9375, 'epoch': 0.26078909733322114}\n",
      "{'loss': 0.9169, 'learning_rate': 5.571428571428572e-06, 'grad_norm': 0.8515625, 'epoch': 0.261630352485909}\n",
      "{'loss': 1.0367, 'learning_rate': 5.428571428571429e-06, 'grad_norm': 0.92578125, 'epoch': 0.2624716076385968}\n",
      "{'loss': 1.085, 'learning_rate': 5.285714285714286e-06, 'grad_norm': 0.859375, 'epoch': 0.2633128627912846}\n",
      "{'loss': 1.0533, 'learning_rate': 5.142857142857143e-06, 'grad_norm': 0.8359375, 'epoch': 0.2641541179439724}\n",
      "{'loss': 1.0656, 'learning_rate': 5e-06, 'grad_norm': 0.890625, 'epoch': 0.2649953730966602}\n",
      "{'loss': 1.1433, 'learning_rate': 4.857142857142858e-06, 'grad_norm': 0.8203125, 'epoch': 0.265836628249348}\n",
      "{'loss': 1.1025, 'learning_rate': 4.714285714285715e-06, 'grad_norm': 0.78125, 'epoch': 0.26667788340203585}\n",
      "{'loss': 1.0186, 'learning_rate': 4.571428571428572e-06, 'grad_norm': 0.94140625, 'epoch': 0.26751913855472365}\n",
      "{'loss': 1.0707, 'learning_rate': 4.428571428571428e-06, 'grad_norm': 0.8671875, 'epoch': 0.26836039370741144}\n",
      "{'loss': 1.2295, 'learning_rate': 4.285714285714286e-06, 'grad_norm': 0.8671875, 'epoch': 0.2692016488600993}\n",
      "{'loss': 1.0408, 'learning_rate': 4.142857142857143e-06, 'grad_norm': 0.7578125, 'epoch': 0.2700429040127871}\n",
      "{'loss': 0.8987, 'learning_rate': 4.000000000000001e-06, 'grad_norm': 0.90625, 'epoch': 0.27088415916547487}\n",
      "{'loss': 1.0121, 'learning_rate': 3.857142857142857e-06, 'grad_norm': 0.94921875, 'epoch': 0.2717254143181627}\n",
      "{'loss': 1.147, 'learning_rate': 3.7142857142857146e-06, 'grad_norm': 0.8515625, 'epoch': 0.2725666694708505}\n",
      "{'loss': 1.12, 'learning_rate': 3.5714285714285714e-06, 'grad_norm': 0.9765625, 'epoch': 0.2734079246235383}\n",
      "{'loss': 1.1087, 'learning_rate': 3.428571428571429e-06, 'grad_norm': 0.84375, 'epoch': 0.27424917977622615}\n",
      "{'loss': 1.0592, 'learning_rate': 3.2857142857142857e-06, 'grad_norm': 0.796875, 'epoch': 0.27509043492891394}\n",
      "{'loss': 1.1241, 'learning_rate': 3.1428571428571433e-06, 'grad_norm': 0.86328125, 'epoch': 0.27593169008160173}\n",
      "{'loss': 1.1624, 'learning_rate': 3e-06, 'grad_norm': 0.9140625, 'epoch': 0.2767729452342896}\n",
      "{'loss': 1.0611, 'learning_rate': 2.8571428571428573e-06, 'grad_norm': 0.953125, 'epoch': 0.27761420038697737}\n",
      "{'loss': 1.0869, 'learning_rate': 2.7142857142857144e-06, 'grad_norm': 1.0546875, 'epoch': 0.27845545553966516}\n",
      "{'loss': 1.1046, 'learning_rate': 2.5714285714285716e-06, 'grad_norm': 0.89453125, 'epoch': 0.279296710692353}\n",
      "{'loss': 1.0918, 'learning_rate': 2.428571428571429e-06, 'grad_norm': 0.90234375, 'epoch': 0.2801379658450408}\n",
      "{'loss': 1.0725, 'learning_rate': 2.285714285714286e-06, 'grad_norm': 0.94140625, 'epoch': 0.2809792209977286}\n",
      "{'loss': 1.0851, 'learning_rate': 2.142857142857143e-06, 'grad_norm': 0.875, 'epoch': 0.28182047615041644}\n",
      "{'loss': 1.0717, 'learning_rate': 2.0000000000000003e-06, 'grad_norm': 0.80859375, 'epoch': 0.28266173130310424}\n",
      "{'loss': 1.0583, 'learning_rate': 1.8571428571428573e-06, 'grad_norm': 1.2421875, 'epoch': 0.283502986455792}\n",
      "{'loss': 1.0184, 'learning_rate': 1.7142857142857145e-06, 'grad_norm': 0.86328125, 'epoch': 0.2843442416084799}\n",
      "{'loss': 1.2386, 'learning_rate': 1.5714285714285717e-06, 'grad_norm': 0.84765625, 'epoch': 0.28518549676116767}\n",
      "{'loss': 1.121, 'learning_rate': 1.4285714285714286e-06, 'grad_norm': 0.8359375, 'epoch': 0.28602675191385546}\n",
      "{'loss': 1.0645, 'learning_rate': 1.2857142857142858e-06, 'grad_norm': 0.89453125, 'epoch': 0.2868680070665433}\n",
      "{'loss': 1.0478, 'learning_rate': 1.142857142857143e-06, 'grad_norm': 0.90234375, 'epoch': 0.2877092622192311}\n",
      "{'loss': 1.0043, 'learning_rate': 1.0000000000000002e-06, 'grad_norm': 0.98828125, 'epoch': 0.2885505173719189}\n",
      "{'loss': 1.1815, 'learning_rate': 8.571428571428572e-07, 'grad_norm': 0.80859375, 'epoch': 0.28939177252460674}\n",
      "{'loss': 1.0482, 'learning_rate': 7.142857142857143e-07, 'grad_norm': 0.890625, 'epoch': 0.29023302767729453}\n",
      "{'loss': 0.952, 'learning_rate': 5.714285714285715e-07, 'grad_norm': 0.921875, 'epoch': 0.2910742828299823}\n",
      "{'loss': 1.0444, 'learning_rate': 4.285714285714286e-07, 'grad_norm': 0.875, 'epoch': 0.29191553798267017}\n",
      "{'loss': 0.9417, 'learning_rate': 2.8571428571428575e-07, 'grad_norm': 0.8984375, 'epoch': 0.29275679313535796}\n",
      "{'loss': 1.1758, 'learning_rate': 1.4285714285714287e-07, 'grad_norm': 0.8515625, 'epoch': 0.29359804828804575}\n",
      "{'loss': 1.0077, 'learning_rate': 0.0, 'grad_norm': 0.82421875, 'epoch': 0.2944393034407336}\n",
      "Saving model checkpoint to /home/ubuntu/environment/ml/SY/qwen/checkpoint-3500\n",
      "Model parallelism is enabled, saving the model sharded state dict instead of the full state dict.\n",
      "[2025-11-09 00:17:32.007: I neuronx_distributed/trainer/checkpoint.py:144] synced saving of checkpoint adapter_shards began\n",
      "[2025-11-09 00:17:32.177: I neuronx_distributed/trainer/checkpoint.py:192] synced saving of checkpoint adapter_shards completed\n",
      "[2025-11-09 00:17:32.178: I neuronx_distributed/trainer/checkpoint.py:256] no checkpoints to remove.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 3596.9461, 'train_samples_per_second': 1.946, 'train_steps_per_second': 0.973, 'train_loss': 1.0900153418949672, 'epoch': 0.2944393034407336}\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "Consolidating LoRA adapter shards\n",
      "Merging LoRA adapter shards into base model\n",
      "Saving merged model to /home/ubuntu/environment/ml/SY/qwen/merged_model\n",
      "Saving tokenizer to /home/ubuntu/environment/ml/SY/qwen/merged_model\n",
      "Merged model config:\n",
      "Qwen3Model(\n",
      "  (embed_tokens): Embedding(151936, 2048)\n",
      "  (layers): ModuleList(\n",
      "    (0-27): 28 x Qwen3DecoderLayer(\n",
      "      (self_attn): Qwen3Attention(\n",
      "        (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "        (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "        (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "        (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "        (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
      "      )\n",
      "      (mlp): Qwen3MLP(\n",
      "        (gate_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "        (up_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "        (down_proj): Linear(in_features=6144, out_features=2048, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "      (input_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
      "      (post_attention_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
      "    )\n",
      "  )\n",
      "  (norm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
      "  (rotary_emb): Qwen3RotaryEmbedding()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "!torchrun \\\n",
    "  --nnodes 1 \\\n",
    "  --nproc_per_node 2 \\\n",
    "  finetune_emergency_response.py \\\n",
    "  --model_id Qwen/Qwen3-1.7B \\\n",
    "  --tokenizer_id Qwen/Qwen3-1.7B \\\n",
    "  --output_dir ~/environment/ml/SY/qwen \\\n",
    "  --bf16 True \\\n",
    "  --gradient_checkpointing True \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --learning_rate 5e-5 \\\n",
    "  --max_steps 3500 \\\n",
    "  --per_device_train_batch_size 2 \\\n",
    "  --tensor_parallel_size 2 \\\n",
    "  --lora_r 16 \\\n",
    "  --lora_alpha 32 \\\n",
    "  --lora_dropout 0.05 \\\n",
    "  --dataloader_drop_last True \\\n",
    "  --disable_tqdm True \\\n",
    "  --logging_steps 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation\n",
    "\n",
    "After completing the fine-tuning process, the next step is to compile the trained model for AWS Trainium inference using the Hugging Face Optimum Neuron toolchain.\n",
    "Neuron compilation optimizes the model graph and converts it into a Neuron Executable File Format (NEFF), enabling efficient execution on NeuronCores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/commands/env.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/commands/env.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/kvcache/kv_cache_manager.py:24: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..attention.gqa import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:45: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "INFO:Neuron:Generating HLOs for the following models: ['context_encoding_model', 'token_generation_model']\n",
      "[2025-11-09 00:18:44.775: I neuronx_distributed/parallel_layers/parallel_state.py:628] > initializing tensor model parallel with size 2\n",
      "[2025-11-09 00:18:44.775: I neuronx_distributed/parallel_layers/parallel_state.py:629] > initializing pipeline model parallel with size 1\n",
      "[2025-11-09 00:18:44.775: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing context model parallel with size 1\n",
      "[2025-11-09 00:18:44.776: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing data parallel with size 1\n",
      "[2025-11-09 00:18:44.776: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing world size to 2\n",
      "[2025-11-09 00:18:44.776: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x70753c6df6d0>, 'Ascending Ring PG Group')>\n",
      "[2025-11-09 00:18:44.777: I neuronx_distributed/parallel_layers/parallel_state.py:668] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1]]\n",
      "[2025-11-09 00:18:44.777: I neuronx_distributed/parallel_layers/parallel_state.py:669] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1]]\n",
      "[2025-11-09 00:18:44.777: I neuronx_distributed/parallel_layers/parallel_state.py:670] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1]]\n",
      "[2025-11-09 00:18:44.777: I neuronx_distributed/parallel_layers/parallel_state.py:671] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1]]\n",
      "[2025-11-09 00:18:44.777: I neuronx_distributed/parallel_layers/parallel_state.py:672] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1]]\n",
      "[2025-11-09 00:18:44.777: I neuronx_distributed/parallel_layers/parallel_state.py:673] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1]]\n",
      "INFO:Neuron:Generating 1 hlos for key: context_encoding_model\n",
      "INFO:Neuron:Started loading module context_encoding_model\n",
      "INFO:Neuron:Finished loading module context_encoding_model in 0.14237380027770996 seconds\n",
      "INFO:Neuron:generating HLO: context_encoding_model, input example shape = torch.Size([1, 512])\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:299: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs_soft_max, dim=dim, on_cpu=self.on_cpu)\n",
      "Add predicate {{0,+,-1}<i0=[0:128:1]>,+,0}<i1=[0:2048:1]>\n",
      "start lb and ub of  {0,+,-1}<i0=[0:128:1]> is 0 0\n",
      "Add predicate {{255,+,0}<i0=[0:128:1]>,+,-1}<i1=[0:2048:1]>\n",
      "start lb and ub of  {{255,+,0}<i0=[0:128:1]>,+,-1}<i1=[0:2048:1]> is 255 255\n",
      "before build_invert_ranges alive full {\n",
      "  0 <= i1=[0:2048:1] <= 2047; alive full {\n",
      "    0 <= i1=[0:2048:1] <= 2047; 1 <= i0=[0:128:1] <= 127; alive leaf\n",
      "  }\n",
      "  256 <= i1=[0:2048:1] <= 2047; alive {\n",
      "    256 <= i1=[0:2048:1] <= 2047; 0 <= i0=[0:128:1] <= 127; alive full leaf\n",
      "  }\n",
      "}\n",
      "generated domains alive full {\n",
      "  0 <= i1=[0:2048:1] <= 255; alive {\n",
      "    0 <= i1=[0:2048:1] <= 255; 0 <= i0=[0:128:1] <= 0; alive leaf\n",
      "  }\n",
      "}\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:262: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=1, shape=torch.Size([1, 512]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "INFO:Neuron:Finished generating HLO for context_encoding_model in 3.016631841659546 seconds, input example shape = torch.Size([1, 512])\n",
      "INFO:Neuron:Generating 1 hlos for key: token_generation_model\n",
      "INFO:Neuron:Started loading module token_generation_model\n",
      "INFO:Neuron:Finished loading module token_generation_model in 0.0923011302947998 seconds\n",
      "INFO:Neuron:generating HLO: token_generation_model, input example shape = torch.Size([1, 1])\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:299: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs_soft_max, dim=dim, on_cpu=self.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/generation/sampling.py:262: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  probs_cumsum = cumsum(tensor_in=probs, dim=dim, on_cpu=self.on_cpu)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:289: UserWarning: Received an input tensor that was unused or used in a non-static way when traced so the tensor will be ignored. (index=3, shape=torch.Size([1]), dtype=torch.int32). The non-static usage could happen when the traced function expects the input tensor's shape to change (i.e., using the shape to do index slicing), which is not allowed by inference trace expecting static input shapes.\n",
      "  warnings.warn(\n",
      "INFO:Neuron:Finished generating HLO for token_generation_model in 2.320880174636841 seconds, input example shape = torch.Size([1, 1])\n",
      "INFO:Neuron:Generated all HLOs in 5.635690450668335 seconds\n",
      "INFO:Neuron:Starting compilation for the priority HLO\n",
      "INFO:Neuron:'token_generation_model' is the priority model with bucket rank 0\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/libneuronxla/neuron_cc_wrapper.py:283: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.\n",
      "  warnings.warn(SyntaxWarning(\n",
      "Fetched cached neuronxcc-2.20.9961.0+0acef03a/MODULE_de733c6f96020a1e5f56+a9d440f5/model.neff from aws-neuron/optimum-neuron-cache\n",
      "2025-11-09 00:18:50.000942:  219467  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_de733c6f96020a1e5f56+a9d440f5/model.neff\n",
      "Fetched cached neuronxcc-2.20.9961.0+0acef03a/MODULE_de733c6f96020a1e5f56+a9d440f5/wrapped_neff.hlo from aws-neuron/optimum-neuron-cache\n",
      "INFO:Neuron:Done compilation for the priority HLO in 0.7434389591217041 seconds\n",
      "INFO:Neuron:Updating the hlo module with optimized layout\n",
      "INFO:Neuron:Done optimizing weight layout for all HLOs in 0.5334725379943848 seconds\n",
      "INFO:Neuron:Starting compilation for all HLOs\n",
      "INFO:Neuron:Neuron compiler flags: --auto-cast=none --model-type=transformer --tensorizer-options='--enable-ccop-compute-overlap --cc-pipeline-tiling-factor=2 --vectorize-strided-dma ' -O2  --lnc=1 --logfile=/tmp/nxd_model/context_encoding_model/_tp0_bk0/log-neuron-cc.txt\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/libneuronxla/neuron_cc_wrapper.py:245: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.\n",
      "  warnings.warn(SyntaxWarning(\n",
      "Fetched cached neuronxcc-2.20.9961.0+0acef03a/MODULE_057bc784fc164fb34d3e+ed72d204/model.neff from aws-neuron/optimum-neuron-cache\n",
      "2025-11-09 00:18:52.000205:  219467  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_057bc784fc164fb34d3e+ed72d204/model.neff\n",
      "INFO:Neuron:Finished Compilation for all HLOs in 0.5105960369110107 seconds\n",
      "Fetched cached neuronxcc-2.20.9961.0+0acef03a/MODULE_e3031c3c114f7c905db7+ae6a382b/model.neff from aws-neuron/optimum-neuron-cache\n",
      "neuronxcc-2.20.9961.0+0acef03a/MODULE_e3031c3c114f7c905db7+ae6a382b/wrapped_neff.hlo not found in aws-neuron/optimum-neuron-cache: the corresponding graph will be recompiled. This may take up to one hour for large models.\n",
      "INFO:Neuron:Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_e3031c3c114f7c905db7+ae6a382b/model.neff\n",
      "INFO:Neuron:Done preparing weight layout transformation\n",
      "INFO:Neuron:Finished building model in 8.074891328811646 seconds\n",
      "Configuration saved in /home/ubuntu/environment/ml/SY/qwen/compiled_model/neuron_config.json\n",
      "INFO:Neuron:Sharding Weights for ranks: 0...1\n",
      "[2025-11-09 00:18:52.927: I neuronx_distributed/parallel_layers/parallel_state.py:628] > initializing tensor model parallel with size 2\n",
      "[2025-11-09 00:18:52.927: I neuronx_distributed/parallel_layers/parallel_state.py:629] > initializing pipeline model parallel with size 1\n",
      "[2025-11-09 00:18:52.927: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing context model parallel with size 1\n",
      "[2025-11-09 00:18:52.927: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing data parallel with size 1\n",
      "[2025-11-09 00:18:52.927: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing world size to 2\n",
      "[2025-11-09 00:18:52.928: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x70753c6df6d0>, 'Ascending Ring PG Group')>\n",
      "[2025-11-09 00:18:52.928: I neuronx_distributed/parallel_layers/parallel_state.py:668] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0, 1]]\n",
      "[2025-11-09 00:18:52.928: I neuronx_distributed/parallel_layers/parallel_state.py:669] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0], [1]]\n",
      "[2025-11-09 00:18:52.928: I neuronx_distributed/parallel_layers/parallel_state.py:670] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0], [1]]\n",
      "[2025-11-09 00:18:52.928: I neuronx_distributed/parallel_layers/parallel_state.py:671] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0], [1]]\n",
      "[2025-11-09 00:18:52.928: I neuronx_distributed/parallel_layers/parallel_state.py:672] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0], [1]]\n",
      "[2025-11-09 00:18:52.928: I neuronx_distributed/parallel_layers/parallel_state.py:673] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0], [1]]\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/trace/trace.py:640: UserWarning: Removing redundant keys from checkpoint: []\n",
      "  warnings.warn(f\"Removing redundant keys from checkpoint: {keys_to_delete}\")\n",
      "INFO:Neuron:Done Sharding weights in 17.900464302001637\n"
     ]
    }
   ],
   "source": [
    "!optimum-cli export neuron \\\n",
    "  --model /home/ubuntu/environment/ml/SY/qwen/merged_model \\\n",
    "  --task text-generation \\\n",
    "  --sequence_length 512 \\\n",
    "  --batch_size 1 \\\n",
    "  /home/ubuntu/environment/ml/SY/qwen/compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "We will install the Optimum Neuron vllm library.  Then, run inference using the compiled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: optimum-neuron[vllm] in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: transformers~=4.51.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (4.51.3)\n",
      "Requirement already satisfied: accelerate==1.8.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.8.1)\n",
      "Requirement already satisfied: optimum~=1.24.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.24.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.29.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (0.33.4)\n",
      "Requirement already satisfied: numpy<=1.25.2,>=1.22.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.25.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (3.20.3)\n",
      "Requirement already satisfied: vllm==0.9.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (0.9.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (25.0)\n",
      "Requirement already satisfied: psutil in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (2.7.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (0.5.3)\n",
      "Requirement already satisfied: regex in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2025.7.34)\n",
      "Requirement already satisfied: cachetools in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (6.2.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (4.67.1)\n",
      "Requirement already satisfied: blake3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.0.8)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (9.0.0)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.21.4)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.116.1)\n",
      "Requirement already satisfied: aiohttp in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.12.15)\n",
      "Requirement already satisfied: openai<=1.90.0,>=1.52.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.90.0)\n",
      "Requirement already satisfied: pydantic>=2.10 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2.11.7)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.22.1)\n",
      "Requirement already satisfied: pillow in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (11.3.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (7.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.12.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.10.12)\n",
      "Requirement already satisfied: llguidance<0.8.0,>=0.7.11 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.7.30)\n",
      "Requirement already satisfied: outlines==0.1.11 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.2.2)\n",
      "Requirement already satisfied: xgrammar==0.1.19 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.1.19)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (4.14.1)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.18.0)\n",
      "Requirement already satisfied: partial-json-parser in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.2.1.1.post6)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (27.0.0)\n",
      "Requirement already satisfied: msgspec in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.19.0)\n",
      "Requirement already satisfied: gguf>=0.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.17.1)\n",
      "Requirement already satisfied: mistral_common>=1.6.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from mistral_common[opencv]>=1.6.2->vllm==0.9.2->optimum-neuron[vllm]) (1.8.5)\n",
      "Requirement already satisfied: opencv-python-headless>=4.11.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (4.11.0.86)\n",
      "Requirement already satisfied: einops in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.8.1)\n",
      "Requirement already satisfied: compressed-tensors==0.10.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.10.2)\n",
      "Requirement already satisfied: depyf==0.18.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.1.1)\n",
      "Requirement already satisfied: watchfiles in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.1.1)\n",
      "Requirement already satisfied: python-json-logger in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.3.0)\n",
      "Requirement already satisfied: scipy in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.12.0)\n",
      "Requirement already satisfied: ninja in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.13.0)\n",
      "Requirement already satisfied: pybase64 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.4.2)\n",
      "Requirement already satisfied: numba==0.61.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.61.2)\n",
      "Requirement already satisfied: ray!=2.44.*,>=2.43.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (2.51.1)\n",
      "Requirement already satisfied: torchaudio==2.7.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2.7.0)\n",
      "Requirement already satisfied: torchvision==0.22.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.22.0)\n",
      "Requirement already satisfied: xformers==0.0.30 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.0.30)\n",
      "Requirement already satisfied: astor in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from depyf==0.18.0->vllm==0.9.2->optimum-neuron[vllm]) (0.8.1)\n",
      "Requirement already satisfied: dill in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from depyf==0.18.0->vllm==0.9.2->optimum-neuron[vllm]) (0.3.8)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from numba==0.61.2->vllm==0.9.2->optimum-neuron[vllm]) (0.44.0)\n",
      "Requirement already satisfied: interegular in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (5.6.3)\n",
      "Requirement already satisfied: referencing in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (4.25.0)\n",
      "Requirement already satisfied: pycountry in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (20250909)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (0.1.26)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2.8.8)\n",
      "Requirement already satisfied: fsspec in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (80.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (0.11.1)\n",
      "Requirement already satisfied: sniffio in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.10->vllm==0.9.2->optimum-neuron[vllm]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.10->vllm==0.9.2->optimum-neuron[vllm]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.10->vllm==0.9.2->optimum-neuron[vllm]) (0.4.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface-hub>=0.29.0->optimum-neuron[vllm]) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.47.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.8 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.0.14)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.0.20)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (2.3.0)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.38.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (2.8.0)\n",
      "Requirement already satisfied: typer>=0.15.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.20.0)\n",
      "Requirement already satisfied: rich-toolkit>=0.14.8 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.15.1)\n",
      "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.3.1)\n",
      "Requirement already satisfied: rignore>=0.5.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.7.6)\n",
      "Requirement already satisfied: sentry-sdk>=2.20.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (2.43.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jinja2->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (3.0.2)\n",
      "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.6.2->mistral_common[opencv]>=1.6.2->vllm==0.9.2->optimum-neuron[vllm]) (2.10.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (0.26.0)\n",
      "Requirement already satisfied: click!=8.3.0,>=7.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (8.2.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (1.1.2)\n",
      "Requirement already satisfied: cupy-cuda12x in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (13.6.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.9.2->optimum-neuron[vllm]) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.9.2->optimum-neuron[vllm]) (2.5.0)\n",
      "Requirement already satisfied: rich>=13.7.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (14.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (1.2.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.22.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (15.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (1.20.1)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (0.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optimum-neuron[vllm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-09 00:19:21 [__init__.py:39] Available plugins for group vllm.platform_plugins:\n",
      "INFO 11-09 00:19:21 [__init__.py:41] - optimum_neuron -> optimum.neuron.vllm.plugin:register\n",
      "INFO 11-09 00:19:21 [__init__.py:44] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "INFO:Neuron:Optimum Neuron platform plugin registered for vLLM.\n",
      "INFO:Neuron:Optimum Neuron platform plugin registered for vLLM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-09 00:19:22 [__init__.py:235] Platform plugin optimum_neuron is activated\n",
      "WARNING 11-09 00:19:22 [_custom_ops.py:20] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')\n",
      "INFO 11-09 00:19:30 [config.py:841] This model supports multiple tasks: {'generate', 'classify', 'reward', 'embed'}. Defaulting to 'generate'.\n",
      "INFO 11-09 00:19:30 [config.py:1472] Using max model len 2048\n",
      "WARNING 11-09 00:19:30 [arg_utils.py:1735] device type=neuron is not supported by the V1 Engine. Falling back to V0. \n",
      "INFO 11-09 00:19:33 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.2) with config: model='/home/ubuntu/environment/ml/SY/qwen/compiled_model', speculative_config=None, tokenizer='/home/ubuntu/environment/ml/SY/qwen/compiled_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cpu, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/ubuntu/environment/ml/SY/qwen/compiled_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":1,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 11-09 00:19:34 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/kvcache/kv_cache_manager.py:24: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..attention.gqa import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:45: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "INFO:Neuron:Loading sharded checkpoint from /home/ubuntu/environment/ml/SY/qwen/compiled_model/checkpoint/weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 11-09 00:19:42 [config.py:4861] Current vLLM config is not set.\n",
      "INFO 11-09 00:19:42 [executor_base.py:113] # neuron blocks: 2, # CPU blocks: 0\n",
      "INFO 11-09 00:19:42 [executor_base.py:118] Maximum concurrency for 2048 tokens per request: 2.00x\n",
      "INFO 11-09 00:19:42 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48666d07652497bab1dffb241900e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099be7e2b82a4e67b6d9f64b49de1a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-Nov-09 00:19:42.0213 195463:219957 [1] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):213 CCOM WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "2025-Nov-09 00:19:42.0223 195463:219957 [1] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):354 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2025-Nov-09 00:19:42.0233 195463:219957 [1] ncclResult_t nccl_net_ofi_init_no_atexit_fini_v6(ncclDebugLogger_t):183 CCOM WARN NET/OFI Initializing plugin failed\n",
      "2025-Nov-09 00:19:42.0243 195463:219957 [1] net_plugin.cc:97 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
      "#########################################################\n",
      "### USER ###\n",
      "\n",
      "<|im_start|>system\n",
      "You are a calm, medically accurate first-aid assistant. Give step-by-step help.<|im_end|>\n",
      "<|im_start|>user\n",
      "My friend burned his hand on a hot pan. What should I do immediately?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "### RESPONSE ###\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Stop the burning. If the wound is not bleeding, use a compress wrapped in cloth to cool the burn. If the wound is bleeding, do not use ice. Instead, run hot water over the area for 10 minutes to help stop bleeding. Do not cover or bandage the wound with petroleum jelly. Instead, keep it exposed and clean. If the wound is deep, use a hydrogen peroxide solution to clean it. If the wound is on the top of the hand, you can elevate the hand above the waist to reduce swelling. If the wound is very deep, apply pressure with a clean cloth until bleeding stops. If the hand is numb or weak, notify your friend before you apply any new treatment.\n",
      "-------------------------------------------------------\n",
      "### USER ###\n",
      "\n",
      "<|im_start|>system\n",
      "You are an offline emergency chatbot providing safe, concise first-aid advice.<|im_end|>\n",
      "<|im_start|>user\n",
      "Someone nearby fainted suddenly, whatâ€™s the first thing I should check?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "### RESPONSE ###\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Check for breathing.\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(\n",
    "    model=\"/home/ubuntu/environment/ml/SY/qwen/compiled_model\", #local compiled model\n",
    "    max_num_seqs=1,\n",
    "    max_model_len=2048,\n",
    "    device=\"neuron\",\n",
    "    tensor_parallel_size=2,\n",
    "    override_neuron_config={})\n",
    "\n",
    "prompts = [\n",
    "\"\"\"\n",
    "<|im_start|>system\n",
    "You are a calm, medically accurate first-aid assistant. Give step-by-step help.<|im_end|>\n",
    "<|im_start|>user\n",
    "My friend burned his hand on a hot pan. What should I do immediately?<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\",\n",
    "\"\"\"\n",
    "<|im_start|>system\n",
    "You are an offline emergency chatbot providing safe, concise first-aid advice.<|im_end|>\n",
    "<|im_start|>user\n",
    "Someone nearby fainted suddenly, whatâ€™s the first thing I should check?<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "sampling_params = SamplingParams(max_tokens=2048, temperature=0.75)\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "print(\"#########################################################\")\n",
    "\n",
    "for output in outputs:\n",
    "    print(\"### USER ###\")\n",
    "    print(output.prompt)\n",
    "    print(\"### RESPONSE ###\")\n",
    "    print(output.outputs[0].text)\n",
    "    print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuronx_venv_pytorch_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
